{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create working directory\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\");\n",
    "\n",
    "\n",
    "import os#Miscellaneous operating system interfaces\n",
    "os.chdir(r'C:\\\\Users\\\\rtreichl\\\\Documents\\\\competitions\\\\Santander')  #working directory\n",
    "\n",
    "#%matplotlib inline allows graphics to show below each cell (or graphics in line)\n",
    "# for some reason, %matplotlib inline won't work if comments are made in the same cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd #munging and wrangling\n",
    "import numpy as np  #for arrays, etc.\n",
    "import matplotlib.pyplot as plt #graphs/plots\n",
    "import scipy.stats as stats\n",
    "\n",
    "from itertools import combinations\n",
    "from numpy import array,array_equal\n",
    "\n",
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Model Selection -> Metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#xgboost\n",
    "import xgboost as xgb #xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use dataframes for EDA\n",
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(train.info())\n",
    "print(test.shape)\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#length of train\n",
    "num_train = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine train and test sets\n",
    "df_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#flag values equal to 9999999999 or -999999 as missing\n",
    "\n",
    "#replace as nan\n",
    "\n",
    "col_list=list(test.columns[0:336])\n",
    "for i in col_list:\n",
    "    df_all[i+'_miss'] = np.where(np.logical_or(df_all[i] == 9999999999, df_all[i] ==-999999,),1.0,0.0)\n",
    "    df_all[i]         = np.where(np.logical_or(df_all[i] == 9999999999,df_all[i] == -999999),np.nan,df_all[i])\n",
    "\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#some fields appear to also use -1 as a missing value....but not all\n",
    "minus_one_list=['delta_imp_reemb_var17_1y3','delta_imp_trasp_var17_in_1y3','delta_imp_trasp_var33_in_1y3',\n",
    "'delta_num_reemb_var17_1y3','delta_num_trasp_var17_in_1y3','delta_num_trasp_var33_in_1y3',]\n",
    "for i in minus_one_list:\n",
    "    df_all[i+'_miss'] = np.where(df_all[i] == -1,1.0,df_all[i+'_miss'])\n",
    "    df_all[i]         = np.where(df_all[i] == -1,np.nan,df_all[i])\n",
    "    \n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_all.columns:\n",
    "    if df_all[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_all.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove duplicated columns\n",
    "\n",
    "remove = []\n",
    "c = df_all.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_all[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_all[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_all.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#impute missing values\n",
    "#imputation strategy is most_frequent\n",
    "\n",
    "#imp = preprocessing.Imputer(strategy='most_frequent',axis=1)\n",
    "#imp = preprocessing.Imputer(strategy='median',axis=1)\n",
    "imp = preprocessing.Imputer(strategy='mean',axis=1)\n",
    "\n",
    "\n",
    "for i in list(df_all.columns[2:314]):\n",
    "    temp=pd.DataFrame((imp.fit(df_all[i]).transform(df_all[i])).reshape(-1,1))\n",
    "    df_all[i]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in list(train.columns[2:348]):\n",
    "    stats.probplot(train[i], dist=\"norm\", plot=plt)\n",
    "    plt.title('QQPlot'+i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define train and test set from df_all\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "ID_test = df_test['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=df_train['TARGET']\n",
    "\n",
    "x_train = df_train.drop(['ID','TARGET'],axis=1).values\n",
    "\n",
    "x_test = df_test.drop(['ID','TARGET'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#linear model perform better when all variables are on the same scale\n",
    "#linear models assume all multi-variate data is multivariant normal\n",
    "#pca performs better when data are standardized.\n",
    "\n",
    "#std_scale = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "#x_train   = std_scale.transform(x_train)\n",
    "\n",
    "#x_test    = std_scale.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train['imp_ent_var16_ult1']=np.where(train['imp_ent_var16_ult1'] > 75000,75000,train['imp_ent_var16_ult1'])\n",
    "#train['imp_op_var39_comer_ult1']=np.where(train['imp_op_var39_comer_ult1'] > 8000,8000,train['imp_op_var39_comer_ult1'])\n",
    "#train['imp_op_var39_comer_ult3']=np.where(train['imp_op_var39_comer_ult3'] > 9000,9000,train['imp_op_var39_comer_ult3'])\n",
    "#train['imp_op_var40_comer_ult1']=np.where(train['imp_op_var40_comer_ult1'] > 2600,2600,train['imp_op_var40_comer_ult1'])\n",
    "#imp_op_var40_comer_ult3 6000\n",
    "#imp_op_var40_efect_ult1  900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training and test sets for cross validation\n",
    "x_traincv, x_testcv, y_traincv, y_testcv = cross_validation.train_test_split(x_train,y_train, test_size=0.50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#identify appropriate number of boost rounds\n",
    "\n",
    "def xg_paraml(label,x_train,y_train,x_test,y_test):\n",
    "\n",
    "    for bb in range(475,525,5):\n",
    "        \n",
    "        xgb_train_data = xgb.DMatrix(x_train, np.array(y_train))\n",
    "        xgb_test_data=xgb.DMatrix(x_test)\n",
    "        params={'objective':'binary:logistic','eval_metric' : 'auc','eta': 0.01 ,\n",
    "                        'subsample':1.0, 'nthread' : -1, \n",
    "                #'max_depth':6, 'colsample_bytree':0.3\n",
    "               }\n",
    "        xgb_estimator = xgb.train(params, xgb_train_data, num_boost_round= bb)\n",
    "        pred=xgb_estimator.predict(xgb_train_data)\n",
    "        pred_test=xgb_estimator.predict(xgb_test_data)\n",
    "        metric_tr=roc_auc_score(y_train, pred)\n",
    "        metric_te=roc_auc_score(y_test, pred_test)\n",
    "        print(label+ str(metric_tr) + '   '+\n",
    "              str(metric_te) +\n",
    "              ' boost rounds '+str(bb))\n",
    "\n",
    "xg_paraml(label=' parameter ', x_train=x_traincv,y_train=y_traincv,x_test=x_testcv,y_test=y_testcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#identify optimal parameters\n",
    "\n",
    "def xg_paraml(label,x_train,y_train,x_test,y_test):\n",
    "    cb_list=[0.51,0.52,0.53,0.54,0.55,0.56,0.57,0.58,0.59,0.60,0.61,0.62,0.63, 0.64,0.65,0.66,0.67,0.68,0.69]\n",
    "    \n",
    "    for md in range(5,30,1):\n",
    "        for cb in cb_list:\n",
    "                    xgb_train_data = xgb.DMatrix(x_train, np.array(y_train ))\n",
    "                    xgb_test_data=xgb.DMatrix(x_test)\n",
    "                    params={'objective':'binary:logistic','eval_metric' : 'auc','eta': 0.01 ,\n",
    "                        'subsample':1.0, 'max_depth':md, 'colsample_bytree':cb,'nthreads':-1}\n",
    "                    xgb_estimator = xgb.train(params, xgb_train_data, num_boost_round= 515)\n",
    "                    pred=xgb_estimator.predict(xgb_train_data)\n",
    "                    pred_test=xgb_estimator.predict(xgb_test_data)\n",
    "                    metric_tr=roc_auc_score(y_train, pred)\n",
    "                    metric_te=roc_auc_score(y_test, pred_test)\n",
    "                    print(label+ str(metric_tr) + '   '+str(metric_te) +#' subsample '+str(ss)+\n",
    "                          ' max_depth '+\n",
    "                      str(md)+' colsample '+str(cb))\n",
    "\n",
    "\n",
    "xg_paraml(label=' parameter ', x_train=x_traincv,y_train=y_traincv,x_test=x_testcv,y_test=y_testcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#final model with submission file\n",
    "#def xg_sub(label,x_train,y_train,x_test,parameters):\n",
    "    #xgb parameters\n",
    "    \n",
    "params = {'objective':'binary:logistic','eval_metric' : 'auc', 'eta': 0.01,\n",
    "         'subsample':1.0, 'max_depth':5, 'colsample_bytree':0.6,\n",
    "          'nthread':-1}\n",
    "\n",
    "\n",
    "    #train input matrix\n",
    "xgb_train_data = xgb.DMatrix(x_train, y_train)\n",
    "xgb_test_data  = xgb.DMatrix(x_test)\n",
    "\n",
    "xgb_estimator = xgb.train(params, xgb_train_data, num_boost_round= 515)\n",
    "\n",
    "\n",
    "train_pred=pd.DataFrame(xgb_estimator.predict(xgb_train_data))\n",
    "test_pred =xgb_estimator.predict(xgb_test_data)\n",
    "\n",
    "submission_xg = pd.DataFrame(columns=['ID','TARGET'])\n",
    "submission_xg['ID']=ID_test\n",
    "submission_xg['TARGET']=test_pred\n",
    "submission_xg.to_csv('santander_515_1_5_06_mean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
